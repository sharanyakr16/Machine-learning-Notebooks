{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Transfer Learning in PyTorch</span>\n",
    "\n",
    "This is a tutorial on model creation and transfer learning in [PyTorch](https://pytorch.org/). There are many ways to create/modify a model in PyTorch and we are not going over an exhaustive list. The goal here is to do this task using minimalistic, understandable, and flexible methods. There will be some preprocessing and data loading that is requred for any training but preprocessing is not the focus of this tutorial, hence we go over it very briefly without explanations. Also, we assume the reader is familiar with the basics of the theory of convolutional neural networks. The tutorial sections are:\n",
    "\n",
    "[1. Pre-requisites](#Pre-requisites)\n",
    "\n",
    "[2. Basics of Model Creation](#basics)\n",
    "\n",
    "[3. Finetuning Pretrained Models and Transfer Learning](#transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Pre-requisites'></a>\n",
    "\n",
    "# <span style=\"color:blue\">1. Pre-requisites</span>\n",
    "\n",
    "To continue with the tutorial you will need to import some standard and third party libraries. We recommend that you use [Anaconda](https://www.anaconda.com/download/) for easier package management. Follow this [link](https://conda.io/docs/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands) to create an enviroment and then activate the enviroment. The libraries `numpy`, `jupyter notebook`, and `matplotlib`can be install using `pip`:\n",
    "```\n",
    "pip install library_name\n",
    "```\n",
    "Look at this [link](https://anaconda.org/anaconda/pillow) to install `pillow`. Finally look at the official [PyTorch](https://pytorch.org/) page for appropriate installation for your OS.\n",
    "\n",
    "If you have a GPU with [CUDA](https://developer.nvidia.com/cuda-downloads) capabilities, it can speed up your computations but it is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import os\n",
    "from itertools import chain\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globally set PyTorch device: cuda if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "Here we download and preprocess the [STL10](https://cs.stanford.edu/~acoates/stl10/) as our dataset. The size of this dataset is small which makes it more appealing for transfer learning tasks which is a part of this tutorial. Parts of the code is borrowed from the official PyTorch examples at [PyTorch](https://pytorch.org/). Since, preprocessing is not the focus of the tutorial we go over this part quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a transformation to convert data to tensors, normalize it, and resize it\n",
    "batch_size = 4\n",
    "to_tensor = transforms.ToTensor()\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "resize = transforms.Resize((224,224), interpolation=2)\n",
    "transform_compose = transforms.Compose([resize,to_tensor,normalize])\n",
    "\n",
    "# data folder\n",
    "download_folder = r'C:\\Users\\ehsan\\Downloads\\STL10_data'\n",
    "\n",
    "# get the data \n",
    "trainset = torchvision.datasets.STL10(root = download_folder, split='train',\n",
    "                                      transform = transform_compose, download=True)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.STL10(root = download_folder, split='test',\n",
    "                                      transform = transform_compose, download=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "classes = np.array(['plane','bird','car', 'cat','deer',\n",
    "                    'dog', 'horse', 'monkey', 'ship', 'truck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the images\n",
    "def plots_ims(ims, cols=5, titles=None):\n",
    "    rows = len(ims)//cols if len(ims) % cols == 0 else len(ims)//cols + 1\n",
    "    f = plt.figure(figsize=(18, 3*rows))\n",
    "    ims_np = ims.transpose(1,3).transpose(1,2).numpy()\n",
    "    ims_np_unnormal = np.array([(im-im.min())/(im-im.min()).max() for im in ims_np])\n",
    "    for i in range(len(ims_np_unnormal)):\n",
    "        subplot = f.add_subplot(rows, cols, i+1)\n",
    "        plt.imshow(ims_np_unnormal[i],cmap='gray')\n",
    "        subplot.axis('Off')\n",
    "        if titles is not None:\n",
    "            subplot.set_title(titles[i], fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some samples from the data loader\n",
    "ims, labels = next(iter(trainloader))\n",
    "print('images batch shape and type:',ims.size(), ims.type())\n",
    "plots_ims(ims, titles=classes[labels.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basics'></a>\n",
    "\n",
    "# <span style=\"color:blue\">2. Basics of Model Creation</span>\n",
    "\n",
    "PyTorch gives you a lot of flexibility in model creation/customization which is powerful but could be confusing. In the following, we will go over a simple example to clarify model creation in PyTorch. Operations in PyTorch is usually done in several ways:\n",
    "\n",
    "*Sequential Operations*. In PyTorch you can wrap several operations inside a [sequential](https://pytorch.org/docs/master/nn.html) block. This will automatically run them in order. Using sequential blocks is the easiest way to create your model. Each block can be as simple as one tensor operation or as complex as a full network.\n",
    "\n",
    "*Functional Operations*. PyTorch [functional](https://pytorch.org/docs/master/_modules/torch/nn/functional.html) operations allow us to apply specific operation to previously defined tensors. Functional operations are usually stateless.\n",
    "\n",
    "*Computational Graph*. After defining our parameters (or group of parameters wrapped in a sequential module), we specify how the info is passed between our sequential/functional operations. This creates our [computational graph](http://colah.github.io/posts/2015-08-Backprop/). This step is usually implemented in the `forward()` method of the model.\n",
    "\n",
    "In general, there are two common ways to create our model in PyTorch:\n",
    "\n",
    "- **Sequential model**. Create the parameteres in the `__init__` of the model and wrap them together with the corresponding operations in a sequential block to specify the flow of the info in the computational graph.\n",
    "\n",
    "- **Functional model**. Create the parameteres in the `__init__` of the model. Then in the `forward()` method specify how to use the parameters and functional operations to transform the tensors and pass them between the operations. \n",
    "\n",
    "The sequential models are easier to work with and they are adequate for most of the common tasks. However, the sequential-functional combination gives us more flexibility in creating unconventional models and this is one of the great features of PyTorch. We will focus on Sequential model creation here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Model Creation\n",
    "\n",
    "The most common way to create a convolutional neural network (CNN) in PyTorch is to define the convolutional parameters of the model in a sequential block and define the dense layers in another sequential block. Then stitch them together according to the structure of the model in the `forward()` method. This forms the computational graph. In the following we define a model with 3 convolutional layers and 2 fully connected layers. Remember that you need to reshape the output of the convolutional layers before fed it to the dense layers. We do this using the `view()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_Seq, self).__init__()\n",
    "        # conv layers wrapped in a sequential block\n",
    "        self.convs = nn.Sequential(\n",
    "            # a 2d conv layer with num_channels, out_channels, kernel_size\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            # a ReLU activation function\n",
    "            nn.ReLU(inplace=True),\n",
    "            # maxpooling layer with given kernel_size\n",
    "            nn.MaxPool2d(2),\n",
    "            # here are the second and third conv layers\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "        # dense layers wrapped in a sequential block\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64 * 26 * 26, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, 10))\n",
    "    \n",
    "    # flow of the info in the computional graph\n",
    "    def forward(self, x):\n",
    "        # pass the input to the conv layers       \n",
    "        x = self.convs(x)\n",
    "        # flatten the incoming activities for the dense layer\n",
    "        x = x.view(-1, 64 * 26 * 26)\n",
    "        # pass the data to the dense layers\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new instance of our model\n",
    "net = Net_Seq()\n",
    "# mount the model to GPU (if available)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the model in order to make sure the parameters are set up correctly. Note that printing the model does not provide you with the structure of the model and just list the parameters. At the time of writing this tutorial, PyTorch does not have an official computational graph visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the Model\n",
    "\n",
    "Unlike TensorFlow, PyTorch does not compile the model. Being dyanmic is one of the advantages of PyTorch. But it means we have to be careful about model executation. It is a good idea to pass an input to the model to see if we get the expected output and the data flow in the network is correctly done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random tensor and mount it to the device\n",
    "x = torch.empty(1,3,224,224).cuda()\n",
    "# pass the tensor to the network and examine the output\n",
    "out = net.forward(x).data\n",
    "print('The size of the output is ', out.size())\n",
    "print('The type of the output is ', out.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this compatible with what you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Optimizer\n",
    "\n",
    "After defining the network, we need to define the loss function. Depending on the task in hand, one needs to pick/define the appropriate loss. The cross-entropy loss is the standard loss for classification tasks. One can refer to [PyTorch loss page](https://pytorch.org/docs/master/_modules/torch/nn/modules/loss.html) to find other losses. Note that you can define your own loss too.\n",
    "\n",
    "For the optimizer, we choose [Adam](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) which is one of the standard choices for classification tasks. PyTorch has many options for optimization including the standard SGD and others which can be found [here](https://pytorch.org/docs/master/optim.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss for classification\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# our choice of optimizer with the specified learning rate\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Finally, we need to train our model. In our `train` method, we use the previously created `trainloader` to load new training examples. We mount the image data and the labels to the GPU (if available) to boost the calculations.  \n",
    "\n",
    "Then we feed the image data to the model to get the outputs using the forward method. After that We calculate the loss based on the discrepancy of the output with the true class-ids. We calculate the current loss and we send the error back to the network ([backpropagation](https://en.wikipedia.org/wiki/Backpropagation)) using the optimizer. The rest of the code is to calculate and show the progress information.\n",
    "\n",
    "In the validation phase, we also calculate the number of correct answers. For calculating the predicted label we use the class with maximum probability assigned by the model.\n",
    "\n",
    "Notes:\n",
    "- We need to set the default gradient values to zero. This is because back-propagation in PyTorch is *accumulative* instead of *replaced* which is useful in cases like Recurrent Neural Networks. Here, we are not using an accumulative gradient so we set it to zero on each iteration.\n",
    "- We use dropouts in the forward pass as a regularizer but in the evaluation phase, we do not need dropout. Such matters can be addressed by setting the model to `train()` or `eval()` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss, num_epochs=4):\n",
    "    for epoch in range(num_epochs):\n",
    "        # set the model to training mode\n",
    "        model.train()\n",
    "        loss_sum = 0.0\n",
    "        # loop over the data batches\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, class_ids = data\n",
    "            # mount the data to gpu (if availabe)\n",
    "            inputs, class_ids = inputs.to(device), class_ids.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            # loss\n",
    "            temp_loss = loss(outputs, class_ids)\n",
    "            # backprop\n",
    "            temp_loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            loss_sum += temp_loss.item()\n",
    "            if i % 200 == 199:\n",
    "                print('| epoch: %d | %3d*%5d images | loss = %.3f' %\n",
    "                      (epoch + 1, batch_size , i + 1, loss_sum / 200))\n",
    "                loss_sum = 0.0\n",
    "        \n",
    "        # test the model accuracy on the validation data\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, class_ids = data\n",
    "            inputs, class_ids = inputs.to(device), class_ids.to(device)\n",
    "            # no need to calculate gradients in validation phase\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                temp_loss = loss(outputs, class_ids)\n",
    "                val_loss += temp_loss.item()\n",
    "                # get the index of the max log-probability\n",
    "                preds = outputs.max(1, keepdim=True)[1]\n",
    "                # get the ratio of correct predictions\n",
    "                correct += preds.eq(class_ids.view_as(preds)).long().cpu().sum()\n",
    "        # average of the loss\n",
    "        val_loss /= i\n",
    "        # print info\n",
    "        print('\\n | Test loss = {:.3f} | Test accuracy = {:.0f}% \\n'.format(\n",
    "            val_loss, 100. * correct / len(testloader.dataset)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net,optimizer,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get around 45% accuracy with our model. This is not bad cosidering 10% chance of random answers being correct and the fact that the data set is small. One can get better results by implementing better network architecture or data augmentation. But that is the subject of another tutorial. Here, we will use a more effective method which is *transfer learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='transfer'></a>\n",
    "\n",
    "# <span style=\"color:blue\">3. Finetuning Pretrained Models and Transfer Learning</span>\n",
    "\n",
    "In this section, we leverage the filters learnt in a standard deep architecture trained on a large data set such as ImageNet to get better results in our small data set. This strategy is called **transfer learning** and it is one of the most effective approaches in solving deep learning problems. Here we use a VGG16 network. Other architectures can be used very similarly. One can find more models from [here](https://github.com/pytorch/vision/tree/master/torchvision/models). \n",
    "\n",
    "Firstly, we download the weights of the pretrained model and store them in the `pretrained_model`. Then by calling the `children()` method (or `named_children()`), we can access the weights. In this case, model is separated into two sequential blocks: convolutional block and fully connected (classifier) block. Note that one can call `new_instance = torchvision.models.model_name(pretrained=True)` to create a new instance of the pretrained model and by calling/printing the instance, you can see the parameters of the model.\n",
    "\n",
    "Here, we use only the convolutional block of the pretrained model. Using `nn.Sequential()` we can wrap these parameters to a new block in our own network. Then we add our own fully connected layers that we will train (finetune) later. Note that the number of the nodes in the first fully connected layer should be consistent with the incoming flatten activities from the last convolutional layer. This structure of the network to have two blocks of convolutional and dense is the most common structure for finetuning CNNs in PyTorch. However, we find the equivalent structure in the next seciton that is fully sequential and easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransferNet, self).__init__()\n",
    "        \n",
    "        # load the pretrained model\n",
    "        pretrained_model = torchvision.models.vgg16(pretrained=True)\n",
    "        # store the convolutional layers of the pretrained model\n",
    "        self.pretrained_layers = pretrained_model.features\n",
    "        \n",
    "        # add the new dense layers\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512 * 7 * 7, 4000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4000, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 10))\n",
    "    \n",
    "    # flow of the info in the computional graph\n",
    "    def forward(self, x):\n",
    "        # pass the input to the pretrained convolutional layers       \n",
    "        x = self.pretrained_layers(x)\n",
    "        # flatten the incoming activities\n",
    "        x = x.view(-1, 512 * 7 * 7)\n",
    "        # pass the data to the dense layers\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a new instance of the model\n",
    "fineTune = TransferNet()\n",
    "# mount the model to the GPU\n",
    "fineTune = fineTune.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we finetune the model. The layers borrowed from pretrained VGG are already trained on ImageNet data set and we want to keep them as they are. Hence we only pass the newly added dense layers for training. The rest of the setup is similar to what we had before.\n",
    "\n",
    "Note that another way to specify what parts of the model to train is to set `param.requires_grad = False` for the parts of the network that are not being trained. And then train the whole network. This will allow you to *freeze* or *unfreeze* different parts of the network whenever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the parameters that need to be optimized to the optimizer\n",
    "params = chain(fineTune.dense.parameters())\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(fineTune,optimizer,loss,num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get to 90% accuracy which is pretty impressive considering the small training size and the complexity of the data. This high accuracy is partly because STL10 dataset is very similar to ImageNet but much smaller so our pretrained block was already exposed to many more similar examples. This claifies the power of finetuning if applied to the right problem.\n",
    "\n",
    "Why is test loss smaller than training loss?\n",
    "\n",
    "Next, we visualize some examples of the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the batch and mount it to the GPU (if available) \n",
    "inputs, labels = next(iter(testloader))\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "# predict the classes\n",
    "outputs = fineTune(inputs)\n",
    "preds = outputs.max(1, keepdim=True)[1]\n",
    "pred_classes = classes[preds.cpu().numpy().flatten()]\n",
    "# visualize the predictions\n",
    "plots_ims(inputs.cpu(), titles=pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
